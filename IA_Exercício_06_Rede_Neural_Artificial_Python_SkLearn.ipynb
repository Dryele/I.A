{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "IA - Exercício - 06 - Rede Neural Artificial - Python - SkLearn.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dryele/I.A/blob/main/IA_Exerc%C3%ADcio_06_Rede_Neural_Artificial_Python_SkLearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5tVff4dgKyg"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8xB4G8ogKym"
      },
      "source": [
        "### Carregando Arquivo de Treinamento (.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5MRh5ZfgKyn",
        "outputId": "fa94be11-cf78-4282-96bd-c4cc1b360a4b"
      },
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/alcidesbenicasa/IA---2020.1---Exerc-cio---06---Rede-Neural-Artificial/main/dados_pacientes_treinamento.csv'\n",
        "base_Treinamento = pd.read_csv(url,sep=';', encoding = 'latin1').values\n",
        "print(\"---------------------------------\")\n",
        "print(\"Dados dos Pacientes - TREINAMENTO\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Treinamento)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Treinamento[:, 1:5])\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(\"Classificação Supervisionada\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Treinamento[:, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "Dados dos Pacientes - TREINAMENTO\n",
            "---------------------------------\n",
            "[['João' 'sim' 'sim' 'pequenas' 'sim' 'doente']\n",
            " ['Pedro' 'não' 'não' 'grandes' 'não' 'saudável']\n",
            " ['Maria' 'sim' 'sim' 'pequenas' 'não' 'saudável']\n",
            " ['José' 'sim' 'não' 'grandes' 'sim' 'doente']\n",
            " ['Ana' 'sim' 'não' 'pequenas' 'sim' 'saudável']\n",
            " ['Leila' 'não' 'não' 'grandes' 'sim' 'doente']]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[['sim' 'sim' 'pequenas' 'sim']\n",
            " ['não' 'não' 'grandes' 'não']\n",
            " ['sim' 'sim' 'pequenas' 'não']\n",
            " ['sim' 'não' 'grandes' 'sim']\n",
            " ['sim' 'não' 'pequenas' 'sim']\n",
            " ['não' 'não' 'grandes' 'sim']]\n",
            "----------------------------\n",
            "Classificação Supervisionada\n",
            "----------------------------\n",
            "['doente' 'saudável' 'saudável' 'doente' 'saudável' 'doente']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPpDXy7cgKyp"
      },
      "source": [
        "### Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "L4nvyQJegKyq",
        "outputId": "b49e2828-43d0-469c-e619-a6352a068eb6"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "lb.fit(['sim', 'não'])\n",
        "febre = lb.transform(base_Treinamento[:,1])  \n",
        "enjoo = lb.transform(base_Treinamento[:,2])\n",
        "dores = lb.transform(base_Treinamento[:,4])\n",
        "\n",
        "#Atributos categóricos com valores pequenas e grandes\n",
        "lb.fit(['grandes', 'pequenas'])\n",
        "manchas = lb.transform(base_Treinamento[:,3])\n",
        "\n",
        "#Atributos categóricos com valores saudável e doente\n",
        "lb.fit(['saudável', 'doente'])\n",
        "classes = lb.transform(base_Treinamento[:,5])\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_norm = np.column_stack((febre,enjoo,manchas,dores))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "print(\"Classificação Supervisionada - Numéricos\")\n",
        "print(\"----------------------------------------\")\n",
        "diagnostico_norm = np.hstack((classes))\n",
        "print(diagnostico_norm)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4b5b006e8b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Atributos categóricos com valores sim e não\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'não'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfebre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_Treinamento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0menjoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_Treinamento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_Treinamento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_Treinamento' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4FUfD5gKyr"
      },
      "source": [
        "### Treinamento do Neurônio Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDmPLB5FgKys",
        "outputId": "93cb6106-e485-4e5f-f0bd-5d9b5c8d4e1e"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "# Treinamento do Perceptron a partir dos atributos de entrada e classificações\n",
        "modelo = Perceptron()\n",
        "modelo.fit(atributos_norm, diagnostico_norm)\n",
        "\n",
        "# Acurácia do modelo, que é : 1 - (predições erradas / total de predições)\n",
        "# Acurácia do modelo: indica uma performance geral do modelo. \n",
        "# Dentre todas as classificações, quantas o modelo classificou corretamente;\n",
        "# (VP+VN)/N\n",
        "print('Acurácia: %.3f' % modelo.score(atributos_norm, diagnostico_norm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMwrAoNwgKyt"
      },
      "source": [
        "### ----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKPw4jagKyu"
      },
      "source": [
        "# Validação do Aprendizado "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tUmMoPHgKyv"
      },
      "source": [
        "### Predição Simples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4MRpx9PgKyw",
        "outputId": "c3faeb2c-454e-4ffc-da8f-29239b122303"
      },
      "source": [
        "Luiz = [[0,0,1,1]]\n",
        "print(\"Luiz\", modelo.predict(Luiz))\n",
        "Laura = [[1,1,0,1]]\n",
        "print(\"Laura\", modelo.predict(Laura))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Luiz [0]\n",
            "Laura [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VweXD-8_gKyx"
      },
      "source": [
        "### Predição a partir de base de dados (.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceg0-DfVgKyx",
        "outputId": "2b958914-dbff-48e7-c2e9-b57c6e50d282"
      },
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/alcidesbenicasa/IA---2020.1---Exerc-cio---06---Rede-Neural-Artificial/main/dados_pacientes_teste.csv'\n",
        "base_Testes = pd.read_csv(url,sep=';', encoding = 'latin1').values\n",
        "print(\"----------------------------\")\n",
        "print(\"Dados dos Pacientes - TESTES\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Testes)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Testes[:, 1:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "Dados dos Pacientes - TESTES\n",
            "----------------------------\n",
            "[['João' 'sim' 'sim' 'pequenas' 'sim']\n",
            " ['Pedro' 'não' 'não' 'grandes' 'não']\n",
            " ['Maria' 'sim' 'sim' 'pequenas' 'não']\n",
            " ['José' 'sim' 'não' 'grandes' 'sim']\n",
            " ['Ana' 'sim' 'não' 'pequenas' 'sim']\n",
            " ['Leila' 'não' 'não' 'grandes' 'sim']\n",
            " ['Luis' 'não' 'não' 'pequenas' 'sim']\n",
            " ['Laura' 'sim' 'sim' 'grandes' 'sim']]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[['sim' 'sim' 'pequenas' 'sim']\n",
            " ['não' 'não' 'grandes' 'não']\n",
            " ['sim' 'sim' 'pequenas' 'não']\n",
            " ['sim' 'não' 'grandes' 'sim']\n",
            " ['sim' 'não' 'pequenas' 'sim']\n",
            " ['não' 'não' 'grandes' 'sim']\n",
            " ['não' 'não' 'pequenas' 'sim']\n",
            " ['sim' 'sim' 'grandes' 'sim']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6JQnLaEgKyx"
      },
      "source": [
        "### Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJM8C3IDgKyy",
        "outputId": "57473162-e8e8-449d-e15c-dc6c36c3a8f9"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "lb.fit(['sim', 'não'])\n",
        "febre = lb.transform(base_Testes[:,1])  \n",
        "enjoo = lb.transform(base_Testes[:,2])\n",
        "dores = lb.transform(base_Testes[:,4])\n",
        "\n",
        "#Atributos categóricos com valores pequenas e grandes\n",
        "lb.fit(['grandes', 'pequenas'])\n",
        "manchas = lb.transform(base_Testes[:,3])\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_norm = np.column_stack((febre,enjoo,manchas,dores))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Atributos de Entrada - Numéricos\n",
            "--------------------------------\n",
            "[[1 1 1 1]\n",
            " [0 0 0 0]\n",
            " [1 1 1 0]\n",
            " [1 0 0 1]\n",
            " [1 0 1 1]\n",
            " [0 0 0 1]\n",
            " [0 0 1 1]\n",
            " [1 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QO3B6S3gKyy"
      },
      "source": [
        "### Predição da Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZovGGdmgKyz",
        "outputId": "93b9e92f-f244-4e9e-867b-fe7529cba3be"
      },
      "source": [
        "base_Predicao = modelo.predict((atributos_norm))\n",
        "print(\"Classificações: \", base_Predicao)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificações:  [0 1 1 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ZxJwGAgKyz"
      },
      "source": [
        "### Retorno aos valores Categóricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "EE96lEuPgKy0",
        "outputId": "492de2f5-f6ee-4843-e02d-e223097c657a"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "lb.fit(['sim', 'não'])\n",
        "febre = lb.inverse_transform(atributos_norm[:,0])  \n",
        "enjoo = lb.inverse_transform(atributos_norm[:,1])\n",
        "dores = lb.inverse_transform(atributos_norm[:,3])\n",
        "\n",
        "#Atributos categóricos com valores pequenas e grandes\n",
        "lb.fit(['grandes', 'pequenas'])\n",
        "manchas = lb.inverse_transform(atributos_norm[:,2])\n",
        "\n",
        "#Atributos categóricos com valores saudável e doente\n",
        "lb.fit(['saudável', 'doente'])\n",
        "predicao = lb.inverse_transform(base_Predicao)\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_cat = np.column_stack((base_Testes[:,0],febre,enjoo,manchas,dores,predicao))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_cat)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-dc1ab8fb5b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Atributos categóricos com valores sim e não\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'não'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfebre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matributos_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0menjoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matributos_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matributos_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'atributos_norm' is not defined"
          ]
        }
      ]
    }
  ]
}